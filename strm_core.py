import os
import re
import sqlite3
import requests
import hashlib
import asyncio
from p123.tool import share_iterdir
from datetime import datetime
from colorama import init, Fore, Style
from telegram import Update, BotCommand
from telegram.ext import (
    Application,
    MessageHandler,
    filters,
    ContextTypes,
    CommandHandler,
    ConversationHandler,
)
from urllib.parse import unquote, urlparse
from pathlib import Path
from telegram.request import HTTPXRequest
from httpx import AsyncClient, Limits
from telegram.error import NetworkError

# åˆå§‹åŒ–coloramaï¼ˆæ§åˆ¶å°å½©è‰²è¾“å‡ºï¼‰
init(autoreset=True)

# å¯¹è¯çŠ¶æ€
CONFIRM_CLEAR = 1

# ========================= å…¨å±€é…ç½® =========================
class Config:
    TG_TOKEN = os.getenv("TG_TOKEN", "")     # Telegramæœºå™¨äººä»¤ç‰Œ
    USER_ID = int(os.getenv("USER_ID", ""))  # æˆæƒç”¨æˆ·ID
    BASE_URL = os.getenv("BASE_URL", "")    # STRMæ–‡ä»¶æŒ‡å‘çš„åŸºç¡€URL
    PROXY_URL = os.getenv("PROXY_URL", "")   # ä»£ç†åœ°å€ï¼ˆå¯é€‰ï¼‰
    OUTPUT_ROOT = os.getenv("OUTPUT_ROOT", "./strm_output")# STRMæ–‡ä»¶è¾“å‡ºç›®å½•
    DB_PATH = os.getenv("DB_PATH", "/app/data/strm_records.db") # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    VIDEO_EXTENSIONS = ('.mp4', '.mkv', '.avi', '.mov', '.flv', '.ts', '.iso', '.rmvb', '.m2ts', '.mp3', '.flac')
    SUBTITLE_EXTENSIONS = ('.srt', '.ass', '.sub', '.ssa', '.vtt') # æ”¯æŒçš„å­—å¹•æ‰©å±•å
    MAX_DEPTH = -1 # ç›®å½•éå†æ·±åº¦é™åˆ¶ï¼ˆ-1è¡¨ç¤ºæ— é™åˆ¶ï¼‰
# ========================= æƒé™æ§åˆ¶è£…é¥°å™¨ =========================
# æƒé™éªŒè¯è£…é¥°å™¨ï¼ˆé™é»˜æ¨¡å¼ï¼‰
def restricted(func):
    async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        if user_id != Config.USER_ID:
            return  # æœªæˆæƒç”¨æˆ·ï¼Œç›´æ¥è¿”å›ï¼Œä¸è¿›è¡Œä»»ä½•å“åº”
        return await func(update, context)
    return wrapped
# ========================= æ•°æ®åº“æ“ä½œ =========================
def init_db():
    with sqlite3.connect(Config.DB_PATH) as conn:
        cursor = conn.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='strm_records'")
        if not cursor.fetchone():
            conn.execute('''CREATE TABLE strm_records
                         (id INTEGER PRIMARY KEY AUTOINCREMENT,
                          file_name TEXT NOT NULL,
                          file_size INTEGER NOT NULL CHECK(file_size > 0),
                          md5 TEXT NOT NULL CHECK(length(md5) = 32),
                          s3_key_flag TEXT NOT NULL,
                          strm_path TEXT NOT NULL UNIQUE,
                          status INTEGER DEFAULT 1,
                          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
        else:
            try:
                conn.execute("ALTER TABLE strm_records ADD COLUMN status INTEGER DEFAULT 1")
            except sqlite3.OperationalError:
                pass
        conn.commit()

def check_exists(file_size, md5, s3_key_flag):
    with sqlite3.connect(Config.DB_PATH) as conn:
        cursor = conn.execute('''SELECT id FROM strm_records 
                               WHERE file_size=? AND md5=? AND s3_key_flag=? AND status=1''',
                            (file_size, md5, s3_key_flag))
        return cursor.fetchone()

def add_record(file_name, file_size, md5, s3_key_flag, strm_path):
    with sqlite3.connect(Config.DB_PATH) as conn:
        cursor = conn.execute('''SELECT id FROM strm_records 
                               WHERE strm_path=? AND status=0''',
                            (strm_path,))
        if existing := cursor.fetchone():
            conn.execute('''UPDATE strm_records 
                          SET status=1, file_name=?, file_size=?, md5=?, s3_key_flag=?
                          WHERE id=?''',
                       (file_name, file_size, md5, s3_key_flag, existing[0]))
        else:
            conn.execute('''INSERT INTO strm_records 
                          (file_name, file_size, md5, s3_key_flag, strm_path)
                          VALUES (?, ?, ?, ?, ?)''',
                       (file_name, file_size, md5, s3_key_flag, strm_path))
        conn.commit()
# ========================= æ ¸å¿ƒåŠŸèƒ½ =========================
def delete_records(record_ids):
    """æ‰¹é‡åˆ é™¤è®°å½•"""
    with sqlite3.connect(Config.DB_PATH) as conn:
        try:
            placeholders = ','.join(['?'] * len(record_ids))
            cursor = conn.execute(
                f"UPDATE strm_records SET status=0 WHERE id IN ({placeholders})",
                record_ids
            )
            conn.commit()
            return cursor.rowcount
        except sqlite3.Error as e:
            print(f"æ•°æ®åº“é”™è¯¯: {str(e)}")
            return 0

def get_deleted_ids(attempted_ids):
    """æŸ¥è¯¢å®é™…è¢«åˆ é™¤çš„æœ‰æ•ˆID"""
    with sqlite3.connect(Config.DB_PATH) as conn:
        placeholders = ','.join(['?'] * len(attempted_ids))
        cursor = conn.execute(
            f"SELECT id FROM strm_records WHERE id IN ({placeholders}) AND status=0",
            attempted_ids
        )
        return [row[0] for row in cursor.fetchall()]

def format_ids(ids):
    """æ ¼å¼åŒ–IDæ˜¾ç¤ºï¼ˆè¶…è¿‡10ä¸ªç”¨åŒºé—´è¡¨ç¤ºï¼‰"""
    if len(ids) <= 10:
        return ', '.join(map(str, sorted(ids)))
    
    sorted_ids = sorted(ids)
    ranges = []
    start = end = sorted_ids[0]
    
    for current_id in sorted_ids[1:]:
        if current_id == end + 1:
            end = current_id
        else:
            ranges.append(f"{start}-{end}" if start != end else str(start))
            start = end = current_id
    ranges.append(f"{start}-{end}" if start != end else str(start))
    
    return ' '.join(ranges)

def clear_database():
    with sqlite3.connect(Config.DB_PATH) as conn:
        conn.execute("DELETE FROM strm_records")
        conn.commit()
        return True

def get_all_records():
    with sqlite3.connect(Config.DB_PATH) as conn:
        cursor = conn.execute("SELECT * FROM strm_records WHERE status=1")
        return cursor.fetchall()

def parse_strm_content(content):
    try:
        uri = content.strip()
        if not uri.startswith(("http://", "https://")):
            uri = "http://" + uri
        
        parsed = urlparse(uri)
        path_part = parsed.path.lstrip('/')
        query_part = parsed.query
        
        name_part, size_str, md5 = path_part.rsplit("|", 2)
        file_size = int(size_str)
        
        if len(md5) != 32 or not all(c in "0123456789abcdef" for c in md5):
            raise ValueError("Invalid MD5 hash")
        
        s3_key_flag = query_part.split("&")[0] if query_part else ""
        
        return {
            "name": unquote(name_part),
            "file_size": file_size,
            "md5": md5,
            "s3_key_flag": s3_key_flag
        }
    except Exception as e:
        raise ValueError(f"Invalid STRM content: {str(e)}")

def import_strm_files():
    counts = {
        'imported': 0,
        'skipped': 0,
        'invalid': 0,
        'errors': 0
    }

    print(f"{Fore.YELLOW}ğŸšš å¼€å§‹æ‰«æSTRMæ–‡ä»¶ç›®å½•...")
    
    for root, _, files in os.walk(Config.OUTPUT_ROOT):
        for filename in files:
            if not filename.endswith('.strm'):
                continue
            
            strm_path = os.path.abspath(os.path.join(root, filename))
            try:
                with open(strm_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                data = parse_strm_content(content)
                
                if data['file_size'] <= 0 or not data['s3_key_flag']:
                    counts['invalid'] += 1
                    print(f"{Fore.RED}âš ï¸ æ— æ•ˆè®°å½•ï¼š{strm_path}")
                    continue
                
                if check_exists(data['file_size'], data['md5'], data['s3_key_flag']):
                    counts['skipped'] += 1
                    print(f"{Fore.CYAN}â© è·³è¿‡å·²å­˜åœ¨è®°å½•ï¼š{strm_path}")
                    continue
                
                try:
                    add_record(
                        file_name=data['name'],
                        file_size=data['file_size'],
                        md5=data['md5'],
                        s3_key_flag=data['s3_key_flag'],
                        strm_path=strm_path
                    )
                    counts['imported'] += 1
                    print(f"{Fore.GREEN}âœ… å¯¼å…¥æˆåŠŸï¼š{strm_path}")
                except sqlite3.IntegrityError:
                    counts['skipped'] += 1
                    print(f"{Fore.CYAN}â© è·¯å¾„å†²çªï¼š{strm_path}")
                
            except ValueError as e:
                counts['invalid'] += 1
                print(f"{Fore.RED}âš ï¸ è§£æå¤±è´¥ï¼š{strm_path}\n{str(e)}")
            except Exception as e:
                counts['errors'] += 1
                print(f"{Fore.RED}âŒ å¤„ç†å¼‚å¸¸ï¼š{strm_path}\n{str(e)}")
    
    return counts

def generate_strm_files(domain: str, share_key: str, share_pwd: str):
    counts = {
        'video': 0, 
        'subtitle': 0, 
        'error': 0, 
        'skipped': 0,
        'invalid': 0,
        'skipped_ids': []
    }

    print(f"{Fore.YELLOW}ğŸš€ å¼€å§‹å¤„ç† {domain} çš„åˆ†äº«ï¼š{share_key}")

    for info in share_iterdir(share_key, share_pwd, domain=domain,
                            max_depth=Config.MAX_DEPTH, predicate=lambda x: not x["is_dir"]):
        try:
            raw_uri = unquote(info["uri"].split("://", 1)[-1])
            relpath = info["relpath"]
            ext = os.path.splitext(relpath)[1].lower()

            if ext not in Config.VIDEO_EXTENSIONS + Config.SUBTITLE_EXTENSIONS:
                continue

            output_path = os.path.join(Config.OUTPUT_ROOT, relpath)
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            if ext in Config.VIDEO_EXTENSIONS:
                try:
                    if "?" in raw_uri:
                        size_md5, s3_key_flag = raw_uri.split("?", 1)
                    else:
                        size_md5 = raw_uri
                        s3_key_flag = "unknown_" + hashlib.md5(raw_uri.encode()).hexdigest()[:8]

                    parts = size_md5.split("|")
                    if len(parts) >= 3:
                        name_part, size_str, md5 = parts[-3:]
                    else:
                        md5 = "invalid_" + hashlib.md5(size_md5.encode()).hexdigest()
                        size_str = parts[-1] if parts else "0"
                        name_part = os.path.basename(relpath).split('.')[0]

                    file_size = int(size_str) if size_str.isdigit() else 0
                    s3_key_flag = s3_key_flag.split("&")[0]

                    if file_size == 0 or md5.startswith("invalid"):
                        counts['invalid'] += 1
                        print(f"{Fore.RED}âš ï¸ æ— æ•ˆæ–‡ä»¶è®°å½•ï¼š{relpath}")
                        continue

                    strm_path = os.path.abspath(os.path.splitext(output_path)[0] + '.strm')

                    if existing := check_exists(file_size, md5, s3_key_flag):
                        counts['skipped'] += 1
                        counts['skipped_ids'].append(existing[0])
                        print(f"{Fore.CYAN}â© è·³è¿‡é‡å¤æ–‡ä»¶ [ID:{existing[0]}]: {relpath}")
                        continue

                    with open(strm_path, 'w', encoding='utf-8') as f:
                        f.write(f"{Config.BASE_URL}/{name_part}|{file_size}|{md5}?{s3_key_flag}")
                    
                    add_record(os.path.basename(relpath), file_size, md5, s3_key_flag, strm_path)
                    counts['video'] += 1
                    print(f"{Fore.GREEN}âœ… è§†é¢‘æ–‡ä»¶ï¼š{relpath}")

                except sqlite3.IntegrityError as e:
                    counts['error'] += 1
                    print(f"{Fore.RED}âŒ æ•°æ®åº“å†²çªï¼š{relpath}\n{str(e)}")
                except Exception as parse_error:
                    counts['error'] += 1
                    print(f"{Fore.RED}âŒ å¤„ç†å¤±è´¥ï¼š{relpath}\n{str(parse_error)}")

            elif ext in Config.SUBTITLE_EXTENSIONS:
                try:
                    download_url = f"https://{domain}/{raw_uri}"
                    for retry in range(3):
                        try:
                            response = requests.get(
                                download_url,
                                headers={'User-Agent': 'Mozilla/5.0', 'Referer': f'https://{domain}/'},
                                timeout=20
                            )
                            response.raise_for_status()
                            
                            with open(output_path, 'wb') as f:
                                f.write(response.content)
                            counts['subtitle'] += 1
                            print(f"{Fore.BLUE}ğŸ“ å­—å¹•æ–‡ä»¶ï¼š{relpath}")
                            break
                        except Exception:
                            if retry == 2:
                                counts['error'] += 1
                                print(f"{Fore.RED}âŒ ä¸‹è½½å¤±è´¥ï¼š{relpath}")
                except Exception as e:
                    counts['error'] += 1
                    print(f"{Fore.RED}âŒ å­—å¹•å¤„ç†å¤±è´¥ï¼š{relpath}\n{str(e)}")

        except Exception as e:
            counts['error'] += 1
            print(f"{Fore.RED}âŒ å…¨å±€å¼‚å¸¸ï¼š{relpath}\n{str(e)}")
    
    return counts

# ========================= Telegramå¤„ç†å™¨ =========================

def format_duplicate_ids(ids):
    if not ids:
        return "æ— "
    
    ids = sorted(set(ids))
    ranges = []
    start = end = ids[0]
    
    for current in ids[1:]:
        if current == end + 1:
            end = current
        else:
            ranges.append(f"{start}-{end}" if start != end else str(start))
            start = end = current
    ranges.append(f"{start}-{end}" if start != end else str(start))
    
    merged_ranges = []
    for r in ranges:
        if '-' in r:
            s, e = map(int, r.split('-'))
            if merged_ranges and '-' in merged_ranges[-1]:
                last_s, last_e = map(int, merged_ranges[-1].split('-'))
                if last_e + 1 == s:
                    merged_ranges[-1] = f"{last_s}-{e}"
                    continue
            merged_ranges.append(r)
        else:
            merged_ranges.append(r)
    
    return ' '.join(merged_ranges) if merged_ranges else "æ— "

@restricted
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†123ç½‘ç›˜é“¾æ¥"""
    msg = update.message.text
    # åŒ¹é…åˆ†äº«é“¾æ¥æ ¼å¼
    pattern = r'(https?://[^\s/]+/s/)([a-zA-Z0-9\-_]+)(?:[\s\S]*?(?:æå–ç |å¯†ç |code)[\s:ï¼š=]*(\w{4}))?'    
    if not (match := re.search(pattern, msg, re.IGNORECASE)):
        return
    
    domain = urlparse(match.group(1)).netloc
    share_key = match.group(2)
    share_pwd = match.group(3) or ""

    await update.message.reply_text(f"ğŸ”„ å¼€å§‹ç”Ÿæˆ {share_key} çš„STRM...")

    try:
        if not re.match(r'^[a-zA-Z0-9\-_]+$', share_key):
            raise ValueError(f"æ— æ•ˆåˆ†äº«ç æ ¼å¼ï¼š{share_key}")
            
        start_time = datetime.now()
        report = generate_strm_files(domain, share_key, share_pwd)
        id_ranges = format_duplicate_ids(report['skipped_ids'])
        
        result_msg = (
            f"âœ… å¤„ç†å®Œæˆï¼\n"
            f"â±ï¸ è€—æ—¶: {(datetime.now() - start_time).total_seconds():.1f}ç§’\n"
            f"ğŸ¬ è§†é¢‘: {report['video']} | ğŸ“ å­—å¹•: {report['subtitle']}\n"
            f"â© è·³è¿‡é‡å¤: {report['skipped']} | é‡å¤ID: {id_ranges}"
        )
        if report['invalid']:
            result_msg += f"\nâš ï¸ æ— æ•ˆè®°å½•: {report['invalid']}ä¸ª"
        if report['error']:
            result_msg += f"\nâŒ å¤„ç†é”™è¯¯: {report['error']}ä¸ª"
            
        await update.message.reply_text(result_msg)
    except Exception as e:
        await update.message.reply_text(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")

@restricted
async def handle_delete(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†åˆ é™¤å‘½ä»¤ï¼Œæ”¯æŒæ‰¹é‡IDå’ŒåŒºé—´"""
    if not context.args:
        await update.message.reply_text(
            "âŒ ç”¨æ³•ç¤ºä¾‹ï¼š\n"
            "å•ä¸ªIDï¼š/delete 664\n"
            "å¤šä¸ªIDï¼š/delete 664 665 667\n"
            "åŒºé—´IDï¼š/delete 664-670\n"
            "æ··åˆæ¨¡å¼ï¼š/delete 664-670 675 680-685"
        )
        return

    raw_ids = []
    for arg in context.args:
        if '-' in arg:
            try:
                start, end = sorted(map(int, arg.split('-')))
                raw_ids.extend(range(start, end + 1))
            except:
                await update.message.reply_text(f"âŒ æ— æ•ˆåŒºé—´æ ¼å¼ï¼š{arg}")
                return
        else:
            try:
                raw_ids.append(int(arg))
            except:
                await update.message.reply_text(f"âŒ æ— æ•ˆIDæ ¼å¼ï¼š{arg}")
                return

    unique_ids = list({x for x in raw_ids if x > 0})
    if not unique_ids:
        await update.message.reply_text("âš ï¸ æœªæä¾›æœ‰æ•ˆID")
        return

    try:
        deleted_count = delete_records(unique_ids)
        failed_count = len(unique_ids) - deleted_count
        
        result = [
            f"ğŸ—‘ï¸ è¯·æ±‚åˆ é™¤ï¼š{len(unique_ids)} ä¸ªè®°å½•",
            f"âœ… æˆåŠŸåˆ é™¤ï¼š{deleted_count} ä¸ª",
            f"âŒ æœªæ‰¾åˆ°è®°å½•ï¼š{failed_count} ä¸ª"
        ]
        
        if deleted_count > 0:
            success_ids = get_deleted_ids(unique_ids)
            result.append(f"æˆåŠŸIDï¼š{format_ids(success_ids)}")
            
        if failed_count > 0:
            failed_ids = list(set(unique_ids) - set(success_ids))
            result.append(f"å¤±è´¥IDï¼š{format_ids(failed_ids)}")

        await update.message.reply_text('\n'.join(result))
        
    except Exception as e:
        await update.message.reply_text(f"âŒ åˆ é™¤æ“ä½œå¼‚å¸¸ï¼š{str(e)}")

@restricted
async def handle_clear_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "âš ï¸ ç¡®è®¤è¦æ¸…ç©ºæ‰€æœ‰æ•°æ®åº“è®°å½•å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼\n"
        "è¯·å›å¤'ç¡®è®¤æ¸…ç©º'ç»§ç»­æ“ä½œï¼Œæˆ–å›å¤ä»»æ„å†…å®¹å–æ¶ˆ"
    )
    return CONFIRM_CLEAR

@restricted
async def handle_clear_confirm(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    if text == 'ç¡®è®¤æ¸…ç©º':
        if clear_database():
            await update.message.reply_text("âœ… æ•°æ®åº“å·²æˆåŠŸæ¸…ç©º")
        else:
            await update.message.reply_text("âŒ æ¸…ç©ºæ•°æ®åº“å¤±è´¥")
    else:
        await update.message.reply_text("âŒ å·²å–æ¶ˆæ¸…ç©ºæ“ä½œ")
    return ConversationHandler.END

@restricted
async def cancel_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("âŒ å·²å–æ¶ˆæ¸…ç©ºæ“ä½œ")
    return ConversationHandler.END

@restricted
async def handle_restore(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        success = 0
        failed = 0
        records = get_all_records()
        
        if not records:
            await update.message.reply_text("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰å¯æ¢å¤çš„è®°å½•")
            return

        await update.message.reply_text(f"ğŸ”„ å¼€å§‹æ¢å¤ {len(records)} ä¸ªSTRMæ–‡ä»¶...")
        
        for record in records:
            try:
                strm_path = Path(record[5])
                uri = f"{Config.BASE_URL}/{record[1]}|{record[2]}|{record[3]}?{record[4]}"
                
                if strm_path.exists():
                    continue
                
                strm_path.parent.mkdir(parents=True, exist_ok=True)
                with open(strm_path, 'w') as f:
                    f.write(uri)
                success += 1
                
            except Exception as e:
                print(f"æ¢å¤å¤±è´¥ ID:{record[0]} {str(e)}")
                failed += 1

        result_msg = (
            f"âœ… æ¢å¤å®Œæˆ\n"
            f"æˆåŠŸæ¢å¤: {success} ä¸ª\n"
            f"æ¢å¤å¤±è´¥: {failed} ä¸ª"
        )
        await update.message.reply_text(result_msg)
        
    except Exception as e:
        await update.message.reply_text(f"âŒ æ¢å¤å¤±è´¥ï¼š{str(e)}")

@restricted
async def handle_import(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        start_time = datetime.now()
        report = import_strm_files()
        
        result_msg = (
            f"ğŸ“¦ å¯¼å…¥å®Œæˆï¼\n"
            f"â±ï¸ è€—æ—¶: {(datetime.now() - start_time).total_seconds():.1f}ç§’\n"
            f"ğŸ†• æ–°å¢è®°å½•: {report['imported']}\n"
            f"â© è·³è¿‡è®°å½•: {report['skipped']}\n"
            f"âš ï¸ æ— æ•ˆæ–‡ä»¶: {report['invalid']}\n"
            f"âŒ å¤„ç†é”™è¯¯: {report['errors']}"
        )
        await update.message.reply_text(result_msg)
    except Exception as e:
        await update.message.reply_text(f"âŒ å¯¼å…¥å¤±è´¥ï¼š{str(e)}")

async def post_init(application: Application):
    commands = [
        BotCommand("delete", "åˆ é™¤æŒ‡å®šIDçš„è®°å½•"),
        BotCommand("clear", "æ¸…ç©ºæ•°æ®åº“è®°å½•"),
        BotCommand("restore", "æ¢å¤STRMæ–‡ä»¶åˆ°æœ¬åœ°"),
        BotCommand("import", "å¯¼å…¥STRMæ–‡ä»¶åˆ°æ•°æ®åº“")
    ]
    await application.bot.set_my_commands(commands)
    print(f"{Fore.CYAN}ğŸ“± Telegramèœå•å·²åŠ è½½")

# ========================= ä¸»ç¨‹åºå…¥å£ =========================
# ========================= ä¸»ç¨‹åºå…¥å£ =========================
if __name__ == "__main__":
    init_db()
    os.makedirs(Config.OUTPUT_ROOT, exist_ok=True)
    
    # åˆ›å»ºè‡ªå®šä¹‰è¯·æ±‚é…ç½®ï¼ˆä¿®æ”¹åï¼‰
    from httpx import Limits
    request = HTTPXRequest(
        connection_pool_size=20,
        connect_timeout=30.0,
        read_timeout=30.0,
        proxy=Config.PROXY_URL if Config.PROXY_URL else None,
        retries=3,
        limits=Limits(max_keepalive_connections=50, max_connections=100)
    )
    
    builder = (
        Application.builder()
        .token(Config.TG_TOKEN)
        .post_init(post_init)
        .get_updates_request(request)
        .connect_timeout(60.0)
        .read_timeout(60.0)
    )
    
    # æ·»åŠ å…¨å±€é”™è¯¯å¤„ç†ï¼ˆæ–°å¢ï¼‰
    async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
        if isinstance(context.error, NetworkError):
            logger.error(f"ç½‘ç»œè¿æ¥å¼‚å¸¸: {context.error}, 10ç§’åè‡ªåŠ¨é‡è¿...")
            await asyncio.sleep(10)
            await app.start()
        else:
            logger.error(f"æœªå¤„ç†çš„å¼‚å¸¸: {context.error}")

    app = builder.build()
    app.add_error_handler(error_handler)
    
    # æ·»åŠ ä¼šè¯å¤„ç†å™¨
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("clear", handle_clear_start)],
        states={
            CONFIRM_CLEAR: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_clear_confirm)
            ]
        },
        fallbacks=[CommandHandler("cancel", cancel_clear)],
    )
    # æ³¨å†Œæ‰€æœ‰å¤„ç†å™¨    
    app.add_handler(CommandHandler("delete", handle_delete))
    app.add_handler(CommandHandler("restore", handle_restore))
    app.add_handler(CommandHandler("import", handle_import))
    app.add_handler(conv_handler)
    app.add_handler(MessageHandler(
    filters.TEXT & 
    ~filters.COMMAND & 
    filters.Regex(r'https?://[^\s/]+/s/[a-zA-Z0-9\-_]+'),
    handle_message
))

    #print(f"{Fore.GREEN}ğŸ¤– TGæœºå™¨äººå·²å¯åŠ¨ | æ•°æ®åº“ï¼š{Config.DB_PATH} | STRMè¾“å‡ºç›®å½•ï¼š{os.path.abspath(Config.OUTPUT_ROOT)} ")
    app.run_polling()
